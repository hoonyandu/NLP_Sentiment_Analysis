{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Friends_BERT&ELECTRA_Trial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f684faad224d4dfab94c4da6c5cd87b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b17037f5c7b4158b89e3bb9e3c3d4df","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7b8f130bb2534edc8cdd6b6b61563e68","IPY_MODEL_da358694d66342c2bbe9e38930179e82"]}},"1b17037f5c7b4158b89e3bb9e3c3d4df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b8f130bb2534edc8cdd6b6b61563e68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7133a781051846e787921fc2e269b69c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe1a606286174be89f048777914b5d64"}},"da358694d66342c2bbe9e38930179e82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e0d6d3d3a7b94dab90b1e2721268cdeb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 1.61MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_916994a45f9d4026bdf06576df6866d2"}},"7133a781051846e787921fc2e269b69c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fe1a606286174be89f048777914b5d64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0d6d3d3a7b94dab90b1e2721268cdeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"916994a45f9d4026bdf06576df6866d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"_Mi-IFaf8d9z"},"source":["# 준비 사항"]},{"cell_type":"code","metadata":{"id":"mrR-4Z6p8f4p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608550727113,"user_tz":-540,"elapsed":7182,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"f3b51083-d9e2-4588-af59-fc75aab592ea"},"source":["# Hugging Face의 트랜스포머 모델을 설치\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 13.7MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 55.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 51.2MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=51525c5f73557119f9db059696b798254c2d6e81b1f9dff21774874085e3443f\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ru7hzfn08pe6"},"source":["# 데이터 로드"]},{"cell_type":"code","metadata":{"id":"kJJV8YLC8rER"},"source":["from google.colab import files\n","files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwCpiZl98rhP","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"ac48fbc3-ca79-4692-e0af-33aa373a7b22"},"source":["!unzip Friends.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  Friends.zip\n","  inflating: Friends/friends_dev.json  \n","  inflating: Friends/friends_test.json  \n","  inflating: Friends/friends_train.json  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gECs0v3mGKrO","executionInfo":{"status":"ok","timestamp":1608551257706,"user_tz":-540,"elapsed":1387,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"476e258a-40fe-4f26-bd69-daf6c8910b44"},"source":["from google.colab import drive\r\n","\r\n","drive.mount('/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive/; to attempt to forcibly remount, call drive.mount(\"/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5pFk-AHM9LHT"},"source":["# train data 전처리"]},{"cell_type":"code","metadata":{"id":"ke6ONO98GcGh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c6BxwDSF86KW"},"source":["import pandas as pd\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"z8iqCTN4GfIl","executionInfo":{"status":"ok","timestamp":1608550888666,"user_tz":-540,"elapsed":1028,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"06636606-df7d-4e76-d5a8-fec0cfe69163"},"source":["friends_test = './en_data.csv'\r\n","test = pd.read_csv(friends_test)\r\n","test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>i_dialog</th>\n","      <th>i_utterance</th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Phoebe</td>\n","      <td>Alright, whadyou do with him?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Monica</td>\n","      <td>Oh! You're awake!</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Joey</td>\n","      <td>Then you gotta come clean with Ma! This is not...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Mr. Tribbiani</td>\n","      <td>Yeah, but this is</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Joey</td>\n","      <td>I don't wanna hear it! Now go to my room!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          utterance\n","0   0  ...                      Alright, whadyou do with him?\n","1   1  ...                                  Oh! You're awake!\n","2   2  ...  Then you gotta come clean with Ma! This is not...\n","3   3  ...                                  Yeah, but this is\n","4   4  ...          I don't wanna hear it! Now go to my room!\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"hyLiKpThGcql"},"source":["friends_train = \"/gdrive/MyDrive/korea_university/2020-2/빅데이터자연어처리기술/final/EmotionLines/Friends/friends_train.json\"\r\n","friends_test = \"/gdrive/MyDrive/korea_university/2020-2/빅데이터자연어처리기술/final/EmotionLines/Friends/friends_test.json\"\r\n","friends_dev = \"/gdrive/MyDrive/korea_university/2020-2/빅데이터자연어처리기술/final/EmotionLines/Friends/friends_dev.json\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"liLCqtdO865-"},"source":["with open(friends_train, encoding = 'utf-8', mode = 'r') as f:\n","  tempArray = json.load(f)\n","\n","train = pd.DataFrame.from_dict(tempArray[0])\n","\n","isFirst = True\n","for arr in tempArray:\n","  if isFirst:\n","    isFirst = False\n","    continue\n","\n","  tempDf = pd.DataFrame.from_dict(arr)\n","  train = train.append(tempDf, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Jy6jDXp9E3K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102114169,"user_tz":-540,"elapsed":570,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"dbaf45d6-5341-43c5-ad80-69d5076d0ec1"},"source":["# 리뷰 문장 추출\n","train_sentences = train['utterance']\n","train_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    also I was the point person on my companys tr...\n","1                     You mustve had your hands full.\n","2                              That I did. That I did.\n","3        So lets talk a little bit about your duties.\n","4                               My duties?  All right.\n","5    Now youll be heading a whole division, so you...\n","6                                               I see.\n","7    But therell be perhaps 30 people under you so...\n","8                                        Good to know.\n","9                                We can go into detail\n","Name: utterance, dtype: object"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"dDxy2m0T9WDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102116962,"user_tz":-540,"elapsed":716,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"8a1dd072-61c7-4ca9-c2f4-5fcbc9dc10ec"},"source":["# Electra의 입력 형식에 맞게 변환\n","train_sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in train_sentences]\n","train_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] also I was the point person on my company\\x92s transition from the KL-5 to GR-6 system. [SEP]',\n"," '[CLS] You must\\x92ve had your hands full. [SEP]',\n"," '[CLS] That I did. That I did. [SEP]',\n"," '[CLS] So let\\x92s talk a little bit about your duties. [SEP]',\n"," '[CLS] My duties?  All right. [SEP]',\n"," '[CLS] Now you\\x92ll be heading a whole division, so you\\x92ll have a lot of duties. [SEP]',\n"," '[CLS] I see. [SEP]',\n"," '[CLS] But there\\x92ll be perhaps 30 people under you so you can dump a certain amount on them. [SEP]',\n"," '[CLS] Good to know. [SEP]',\n"," '[CLS] We can go into detail [SEP]']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"s5goT6XKACZv"},"source":["# 감정을 숫자로 변환\n","def emotion_labeling(emotion):\n","   return{'anger' : 0,'disgust':1,'fear':2, 'joy':3,'neutral':4,'non-neutral':5,'sadness':6,'surprise':7}[emotion]\n","\n","emotion_labels = []\n","\n","for e in train['emotion']:\n","   emotion_labels.append(emotion_labeling(e))\n","\n","train['label'] = emotion_labels\n","train[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdGutf98AIYm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102120601,"user_tz":-540,"elapsed":798,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"d21734f3-8572-4871-b6fe-46204d95e09a"},"source":["# label 추출\n","train_labels = train['label'].values\n","train_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 4, 4, ..., 7, 4, 5])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Z_V1EzVgAMby","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102126527,"user_tz":-540,"elapsed":5213,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"0436404f-5095-490e-b37d-1563422a5e99"},"source":["from transformers import ElectraTokenizer, ElectraForSequenceClassification\n","import torch\n","\n","# Electra의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","train_tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n","\n","print (train_sentences[0])\n","print (train_tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] also I was the point person on my companys transition from the KL-5 to GR-6 system. [SEP]\n","['[CLS]', 'also', 'I', 'was', 'the', 'point', 'person', 'on', 'my', 'company', '##s', 'transition', 'from', 'the', 'K', '##L', '-', '5', 'to', 'GR', '-', '6', 'system', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iHxCfzHSBxzx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102129067,"user_tz":-540,"elapsed":1179,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"2c9c9e58-640e-43fd-99e2-bdcc56a036d9"},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 256\n","\n","# 토큰을 숫자 인덱스로 변환\n","train_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in train_tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","train_input_ids[0]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  101, 10379,   146, 10134, 10105, 12331, 15042, 10135, 15127,\n","       12100, 10107, 35959, 10188, 10105,   148, 11369,   118,   126,\n","       10114, 58787,   118,   127, 11787,   119,   102,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"gcw7a4QnCZeV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102134271,"user_tz":-540,"elapsed":2653,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"13061bec-5ff9-4ad4-fbb7-c7bfc452fba0"},"source":["# 어텐션 마스크 초기화\n","train_attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 ELECTRA 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in train_input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    train_attention_masks.append(seq_mask)\n","\n","print(train_attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tknBvYYcCiLe"},"source":["# pytorch 텐서로 변환\n","train_inputs = torch.tensor(train_input_ids)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_attention_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXTVwCIqEbxM"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXSEFgLjCjsf"},"source":["# 전처리- dev"]},{"cell_type":"code","metadata":{"id":"xG84K-CJCm2v"},"source":["with open(friends_dev, encoding = 'utf-8', mode = 'r') as f:\n","  tempArray = json.load(f)\n","\n","dev = pd.DataFrame.from_dict(tempArray[0])\n","\n","isFirst = True\n","for arr in tempArray:\n","  if isFirst:\n","    isFirst = False\n","    continue\n","\n","  tempDf = pd.DataFrame.from_dict(arr)\n","  dev = dev.append(tempDf, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FgIymSLICrFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102210197,"user_tz":-540,"elapsed":986,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"86045025-7832-4412-f159-39cb10e5b553"},"source":["# 리뷰 문장 추출\n","dev_sentences = dev['utterance']\n","dev_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       Oh my God, hes lost it. Hes totally lost it.\n","1                                                What?\n","2    Or! Or, we could go to the bank, close our acc...\n","3                                     Youre a genius!\n","4              Aww, man, now we wont be bank buddies!\n","5                            Now, theres two reasons.\n","6                                                 Hey.\n","7                                                 Hey!\n","8    Ohh, you guys, remember that cute client I tol...\n","9                                              Where?!\n","Name: utterance, dtype: object"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"LnpshdgjCsmi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102210197,"user_tz":-540,"elapsed":980,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"3f0179f8-ff14-4943-ce54-c32e0aaaae1c"},"source":["# Electra의 입력 형식에 맞게 변환\n","dev_sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in dev_sentences]\n","dev_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] Oh my God, he\\x92s lost it. He\\x92s totally lost it. [SEP]',\n"," '[CLS] What? [SEP]',\n"," '[CLS] Or! Or, we could go to the bank, close our accounts and cut them off at the source. [SEP]',\n"," '[CLS] You\\x92re a genius! [SEP]',\n"," '[CLS] Aww, man, now we won\\x92t be bank buddies! [SEP]',\n"," '[CLS] Now, there\\x92s two reasons. [SEP]',\n"," '[CLS] Hey. [SEP]',\n"," '[CLS] Hey! [SEP]',\n"," '[CLS] Ohh, you guys, remember that cute client I told you about? I bit him. [SEP]',\n"," '[CLS] Where?! [SEP]']"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"vo1casBICuuV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102210198,"user_tz":-540,"elapsed":971,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"ade305b0-b122-4ca3-959b-a74912574529"},"source":["# emotion으로 숫자로 변환\n","emotion_labels = []\n","\n","for e in dev['emotion']:\n","   emotion_labels.append(emotion_labeling(e))\n","\n","dev['label'] = emotion_labels\n","dev[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","      <th>emotion</th>\n","      <th>annotation</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Phoebe</td>\n","      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n","      <td>non-neutral</td>\n","      <td>0002120</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Monica</td>\n","      <td>What?</td>\n","      <td>surprise</td>\n","      <td>1000130</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ross</td>\n","      <td>Or! Or, we could go to the bank, close our acc...</td>\n","      <td>neutral</td>\n","      <td>3000200</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Chandler</td>\n","      <td>Youre a genius!</td>\n","      <td>joy</td>\n","      <td>0500000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Joey</td>\n","      <td>Aww, man, now we wont be bank buddies!</td>\n","      <td>sadness</td>\n","      <td>0040100</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Chandler</td>\n","      <td>Now, theres two reasons.</td>\n","      <td>neutral</td>\n","      <td>4000010</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Phoebe</td>\n","      <td>Hey.</td>\n","      <td>neutral</td>\n","      <td>3100010</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>All</td>\n","      <td>Hey!</td>\n","      <td>joy</td>\n","      <td>1300010</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Phoebe</td>\n","      <td>Ohh, you guys, remember that cute client I tol...</td>\n","      <td>neutral</td>\n","      <td>4100000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Rachel</td>\n","      <td>Where?!</td>\n","      <td>surprise</td>\n","      <td>0000050</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    speaker  ... label\n","0    Phoebe  ...     5\n","1    Monica  ...     7\n","2      Ross  ...     4\n","3  Chandler  ...     3\n","4      Joey  ...     6\n","5  Chandler  ...     4\n","6    Phoebe  ...     4\n","7       All  ...     3\n","8    Phoebe  ...     4\n","9    Rachel  ...     7\n","\n","[10 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"JJSFDshJCw01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102210198,"user_tz":-540,"elapsed":961,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"be91b3b0-39fe-4888-8038-9c134776f1af"},"source":["# 라벨 추출\n","dev_labels = dev['label'].values\n","dev_labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 7, 4, ..., 6, 6, 6])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"Ptr8LXfBCy-w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102210730,"user_tz":-540,"elapsed":1484,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"a0417a92-ebfc-48e6-ec52-fd56450706c4"},"source":["# Electra의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","dev_tokenized_texts = [tokenizer.tokenize(sent) for sent in dev_sentences]\n","\n","print (dev_sentences[0])\n","print (dev_tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] Oh my God, hes lost it. Hes totally lost it. [SEP]\n","['[CLS]', 'Oh', 'my', 'God', ',', 'he', '##s', 'lost', 'it', '.', 'He', '##s', 'totally', 'lost', 'it', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WTL0iovBDK9e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102210731,"user_tz":-540,"elapsed":1480,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"85ebf26e-2039-4fe8-eb5f-e779f981ab56"},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 256\n","\n","# 토큰을 숫자 인덱스로 변환\n","dev_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in dev_tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","dev_input_ids = pad_sequences(dev_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","dev_input_ids[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,  22800,  15127,  14015,    117,  10261,  10107,  14172,\n","        10271,    119,  10357,  10107, 110240,  14172,  10271,    119,\n","          102,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"FmyVPo9xDwm3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102211081,"user_tz":-540,"elapsed":1823,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"2a051c2b-edee-4826-8c78-d3989a4c9be2"},"source":["# 어텐션 마스크 초기화\n","dev_attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 Electra 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in dev_input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    dev_attention_masks.append(seq_mask)\n","\n","print(dev_attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XHvOgXoeDyNp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102211081,"user_tz":-540,"elapsed":1817,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"9ad450b6-3ad8-4515-8190-80e666237767"},"source":["# 데이터를 파이토치의 텐서로 변환\n","\n","validation_inputs = torch.tensor(dev_input_ids)\n","validation_labels = torch.tensor(dev_labels)\n","validation_masks = torch.tensor(dev_attention_masks)\t\t\t\t\n","\n","\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])\n","\t\t\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([   101,  22800,  15127,  14015,    117,  10261,  10107,  14172,  10271,\n","           119,  10357,  10107, 110240,  14172,  10271,    119,    102,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0])\n","tensor(5)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9krBeyteE0gz"},"source":["validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xaWxpdzkE_B-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJs8B9QIFApJ"},"source":["# 전처리 - test set"]},{"cell_type":"code","metadata":{"id":"PwZFIWGQFDPB"},"source":["with open(friends_test, encoding = 'utf-8', mode = 'r') as f:\n","  tempArray = json.load(f)\n","\n","test = pd.DataFrame.from_dict(tempArray[0])\n","\n","isFirst = True\n","for arr in tempArray:\n","  if isFirst:\n","    isFirst = False\n","    continue\n","\n","  tempDf = pd.DataFrame.from_dict(arr)\n","  test = test.append(tempDf, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKdBy_WHFE-O","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1608550961980,"user_tz":-540,"elapsed":847,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"60d91969-80bd-4a91-950b-c34a27700fe8"},"source":["test[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>i_dialog</th>\n","      <th>i_utterance</th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Phoebe</td>\n","      <td>Alright, whadyou do with him?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Monica</td>\n","      <td>Oh! You're awake!</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Joey</td>\n","      <td>Then you gotta come clean with Ma! This is not...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Mr. Tribbiani</td>\n","      <td>Yeah, but this is</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Joey</td>\n","      <td>I don't wanna hear it! Now go to my room!</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Chandler</td>\n","      <td>I don?t want him to tell this story for years.</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Ross</td>\n","      <td>Oh, but he will. He still tells the story how ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Monica</td>\n","      <td>I wasn?t escaping.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Ross</td>\n","      <td>Then how did you get caught in the barbed wire?</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>Monica</td>\n","      <td>I was trying to help out a squirrel.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          utterance\n","0   0  ...                      Alright, whadyou do with him?\n","1   1  ...                                  Oh! You're awake!\n","2   2  ...  Then you gotta come clean with Ma! This is not...\n","3   3  ...                                  Yeah, but this is\n","4   4  ...          I don't wanna hear it! Now go to my room!\n","5   5  ...     I don?t want him to tell this story for years.\n","6   6  ...  Oh, but he will. He still tells the story how ...\n","7   7  ...                                 I wasn?t escaping.\n","8   8  ...    Then how did you get caught in the barbed wire?\n","9   9  ...               I was trying to help out a squirrel.\n","\n","[10 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"XIdsESLZFGnS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608550968954,"user_tz":-540,"elapsed":970,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"3de4001c-07f7-44d8-b00c-db84e16414ac"},"source":["# 리뷰 문장 추출\n","sentences = test['utterance']\n","sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                        Alright, whadyou do with him?\n","1                                    Oh! You're awake!\n","2    Then you gotta come clean with Ma! This is not...\n","3                                    Yeah, but this is\n","4            I don't wanna hear it! Now go to my room!\n","5       I don?t want him to tell this story for years.\n","6    Oh, but he will. He still tells the story how ...\n","7                                   I wasn?t escaping.\n","8      Then how did you get caught in the barbed wire?\n","9                 I was trying to help out a squirrel.\n","Name: utterance, dtype: object"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"DyhbgJA3FIF5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608550972127,"user_tz":-540,"elapsed":876,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"0d72acd7-1616-4e70-d8df-f7a2b771781c"},"source":["# ELECTRA의 입력 형식에 맞게 변환\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] Alright, whadyou do with him? [SEP]',\n"," \"[CLS] Oh! You're awake! [SEP]\",\n"," '[CLS] Then you gotta come clean with Ma! This is not right! [SEP]',\n"," '[CLS] Yeah, but this is [SEP]',\n"," \"[CLS] I don't wanna hear it! Now go to my room! [SEP]\",\n"," '[CLS] I don?t want him to tell this story for years. [SEP]',\n"," '[CLS] Oh, but he will. He still tells the story how Monica tried to escape from fat camp. [SEP]',\n"," '[CLS] I wasn?t escaping. [SEP]',\n"," '[CLS] Then how did you get caught in the barbed wire? [SEP]',\n"," '[CLS] I was trying to help out a squirrel. [SEP]']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"hj9Xpg1dFLAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102213266,"user_tz":-540,"elapsed":921,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"7bb0e7c4-e691-4782-f412-987397408d88"},"source":["# 라벨 추출\n","labels = test['label'].values\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([7, 5, 4, ..., 4, 4, 4])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"xHnw3m1_FMYZ","colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["f684faad224d4dfab94c4da6c5cd87b9","1b17037f5c7b4158b89e3bb9e3c3d4df","7b8f130bb2534edc8cdd6b6b61563e68","da358694d66342c2bbe9e38930179e82","7133a781051846e787921fc2e269b69c","fe1a606286174be89f048777914b5d64","e0d6d3d3a7b94dab90b1e2721268cdeb","916994a45f9d4026bdf06576df6866d2"]},"executionInfo":{"status":"ok","timestamp":1608551095265,"user_tz":-540,"elapsed":8551,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"1938978e-493a-4683-f4ad-b3425ea8d44f"},"source":["# ELECTRA의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print (sentences[0])\n","print (tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f684faad224d4dfab94c4da6c5cd87b9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","[CLS] Alright, whadyou do with him? [SEP]\n","['[CLS]', 'Al', '##right', ',', 'w', '##had', '##yo', '##u', 'do', 'with', 'him', '?', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sSW26HQUFWJt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608551145196,"user_tz":-540,"elapsed":1337,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"0ab66d7c-efe6-45e6-99e6-ccc935cda5ad"},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 256\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  101, 10883, 33661,   117,   191, 33796, 15594, 10138, 10149,\n","       10169, 10957,   136,   102,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"3C7E1ey_FXhm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608551148593,"user_tz":-540,"elapsed":822,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"d0021b5e-a08f-4cbd-ce12-3362bd0e9de6"},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 electra 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LYwKjhR2FZCO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608551158894,"user_tz":-540,"elapsed":1051,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"d3b80485-d36f-4313-ced8-7ae39bc83247"},"source":["# 데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","# test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","print(test_inputs[0])\n","# print(test_labels[0])\n","print(test_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([  101, 10883, 33661,   117,   191, 33796, 15594, 10138, 10149, 10169,\n","        10957,   136,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0])\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P6tfGct4FaxE"},"source":["# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMSjArqgFdGS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQ8JfAZ6Fh1Z"},"source":["# 모델 생성"]},{"cell_type":"code","metadata":{"id":"_w6FefwvIYDR"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BR11MqeFi91","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608551382525,"user_tz":-540,"elapsed":2634,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"f50fa819-fae5-4053-dcbd-d35d22525738"},"source":["# GPU 디바이스 이름 구함\n","device_name = tf.test.gpu_device_name()\n","\n","# GPU 디바이스 이름 검사\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XVlooU4DFkEe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608551383234,"user_tz":-540,"elapsed":1060,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"f75ec36a-b705-4bc2-8c33-ed66be797107"},"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EhIWpXlyFlaO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608102229816,"user_tz":-540,"elapsed":13491,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"91db8ed4-a22c-4474-9a48-f62da3c256ef"},"source":["# 분류를 위한 ELECTRA 모델 생성\n","model = ElectraForSequenceClassification.from_pretrained('google/electra-small-generator', num_labels=8)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"LvHHc6XoFyw_"},"source":["from transformers import get_linear_schedule_with_warmup,AdamW\n","\n","# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수\n","epochs = 4\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 학습률을 조금씩 감소시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mItHTct_F1g-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lcyMrx29GEYE"},"source":["# 모델 학습"]},{"cell_type":"code","metadata":{"id":"nXwwxpPTGbbq"},"source":["import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUlPCQ9ZGFlk"},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-gFoRGoGHKM"},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-Nms45dewyS"},"source":["# f1-score parameter\n","from sklearn.metrics import f1_score\n","f1_score_avg = []\n","trues = []\n","preds = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcwnofpgGNEj"},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","\n","        \n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        #\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        trues_flat = label_ids.flatten()\n","        trues.extend(trues_flat)\n","        preds.extend(pred_flat)\n","\n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(trues[:10])\n","    print(preds[:10])\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  f1 score macro: {0: 2f}\".format(f1_score(y_true=trues,y_pred= preds, labels = [0,1,2,3,4,5,6,7], average='macro')))\n","    print(\"  f1 score micro: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='micro')))\n","    print(\"  f1 score weighted: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='weighted')))\n","    print(f\"  f1 score none: {f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average=None)}\")\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","torch.save(model.state_dict(), \"/gdrive/MyDrive/korea_university/2020-2/빅데이터자연어처리기술/final/2020-12-16_Friends_bert_256.dict\")\n","torch.save(model, \"/gdrive/MyDrive/korea_university/2020-2/빅데이터자연어처리기술/final/2020-12-16_Friends_bert_256.sav\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TihX1ZnzGR6D"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hYAU0odGT8C"},"source":["# 테스트셋 평가"]},{"cell_type":"code","metadata":{"id":"49nGvOCiGVcw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2m13eWCYQurk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608104342145,"user_tz":-540,"elapsed":48901,"user":{"displayName":"‍윤채훈[ 컴퓨터정보통신대학원석사과정재학 / 빅데이터융합학과 ]","photoUrl":"","userId":"04155508879667297547"}},"outputId":"732edbd4-0373-46b4-fac8-4e983d47c547"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","   #\n","    pred_flat = np.argmax(logits, axis=1).flatten()\n","    trues_flat = label_ids.flatten()\n","    trues.extend(trues_flat)\n","    preds.extend(pred_flat)\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"  f1 score macro: {0: 2f}\".format(f1_score(y_true=trues,y_pred= preds, labels = [0,1,2,3,4,5,6,7], average='macro')))\n","print(\"  f1 score micro: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='micro')))\n","print(\"  f1 score weighted: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='weighted')))\n","print(f\"  f1 score none: {f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average=None)}\")\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Accuracy: 0.59\n","  f1 score macro:  0.332194\n","  f1 score micro:  0.567416\n","  f1 score weighted:  0.536864\n","  f1 score none: [0.20955316 0.         0.         0.55274725 0.75410765 0.30780347\n"," 0.277666   0.55567568]\n","Test took: 0:00:48\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ek1SQ9Fz5Ccu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"90f43rbcSVOe"},"source":["# 새로운 문장 테스트"]},{"cell_type":"code","metadata":{"id":"9NMhJcUaSXGi"},"source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    # MAX_LEN = 128\n","    MAX_LEN = 256\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    \n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhVUEXqgSaL6"},"source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYBc8mgSSbl-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608551400854,"user_tz":-540,"elapsed":899,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"9e0cff51-ccbc-4d28-a62f-e473afd35dee"},"source":["import numpy as np\n","\n","logits = test_sentences(['Nice job.'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-1.4719529  -1.180453   -1.7436113   0.36653185  3.3078444   1.2102387\n","  -1.1137799  -1.7312894 ]]\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AubeN2d5Is8b"},"source":["test_list = list(np.array(test[\"utterance\"].tolist()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdAm05C6JBdK"},"source":["pred = []\r\n","\r\n","for sen in range(len(test_list)):\r\n","  logits = test_sentences([test_list[sen]])\r\n","\r\n","  print(logits)\r\n","  print(np.argmax(logits))\r\n","  label = np.argmax(logits)\r\n","  pred.extend([label])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EI98N_KrKD97","executionInfo":{"status":"ok","timestamp":1608551780653,"user_tz":-540,"elapsed":1173,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"a9766d1f-b839-4a54-d192-751b05150179"},"source":["len(pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1623"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"QD7x7xr1KFoD"},"source":["e_labels = {'anger' : 0,'disgust':1,'fear':2, 'joy':3,'neutral':4,'non-neutral':5,'sadness':6,'surprise':7}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rk064PJKdVA"},"source":["pred_emo = []\r\n","for pred_label in pred:\r\n","  search_emo = pred_label\r\n","  for emo, label in e_labels.items():  # for name, age in dictionary.iteritems():  (for Python 2.x)\r\n","      if label == search_emo:\r\n","          pred_emo.append(emo)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYumEi_ALAKb","executionInfo":{"status":"ok","timestamp":1608552060968,"user_tz":-540,"elapsed":1004,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"2dd5fd13-9bc5-41bd-9a7a-05e471d92572"},"source":["len(pred_emo)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1623"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"Vq8d7sN9LKZj"},"source":["test_emo[\"Predicted\"] = pred_emo"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"KVg_IMkvMTSD","executionInfo":{"status":"ok","timestamp":1608552533288,"user_tz":-540,"elapsed":1280,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"8c23f75d-6788-479a-afe1-78a36a1983a3"},"source":["test_emo.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>i_dialog</th>\n","      <th>i_utterance</th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Phoebe</td>\n","      <td>Alright, whadyou do with him?</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Monica</td>\n","      <td>Oh! You're awake!</td>\n","      <td>joy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Joey</td>\n","      <td>Then you gotta come clean with Ma! This is not...</td>\n","      <td>non-neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Mr. Tribbiani</td>\n","      <td>Yeah, but this is</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Joey</td>\n","      <td>I don't wanna hear it! Now go to my room!</td>\n","      <td>anger</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  i_dialog  ...                                          utterance    Predicted\n","0   0         0  ...                      Alright, whadyou do with him?      neutral\n","1   1         0  ...                                  Oh! You're awake!          joy\n","2   2         0  ...  Then you gotta come clean with Ma! This is not...  non-neutral\n","3   3         0  ...                                  Yeah, but this is      neutral\n","4   4         0  ...          I don't wanna hear it! Now go to my room!        anger\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"aXJhi3bINElU"},"source":["test_emo.to_csv('en_sample.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIVcsvaGNSiK","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1608552631197,"user_tz":-540,"elapsed":877,"user":{"displayName":"hoony","photoUrl":"","userId":"10011180339829982217"}},"outputId":"5a554926-9fcf-405c-ddc8-45ee760d44a9"},"source":["from google.colab import files\r\n","\r\n","files.download('en_sample.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_3ef1edb5-79bd-4a7c-8ce0-ebd557303739\", \"en_sample.csv\", 110243)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}